{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenimport und Vorbereitung\n",
    "In diesem Abschnitt des Notebooks kümmern wir uns um den Import und die Vorbereitung unserer Daten. Die Daten, mit denen wir arbeiten, stammen aus der \"Open University Learning Analytics Dataset\" (OULAD). Dieses Dataset enthält Informationen über die Interaktionen der Studierenden mit der virtuellen Lernumgebung (VLE) der Open University sowie allgemeine Informationen über die Studierenden selbst.\n",
    "\n",
    "Zwei spezifische Teile des OULAD werden in diesem Notebook verwendet: die studentInfo.csv und die studentVle.csv Dateien. Die studentInfo.csv Datei enthält allgemeine Informationen über die Studierenden, darunter demografische Daten, vorherige Versuche und das Endergebnis des Studiengangs. Die studentVle.csv Datei enthält Daten über die Interaktionen der Studierenden mit der VLE, einschließlich der Anzahl der Klicks und der spezifischen Ressource, auf die zugegriffen wurde.\n",
    "\n",
    "Um die Daten für unsere spätere Analyse vorzubereiten, führen wir zunächst einige grundlegende Datentransformationen durch. Zuerst entfernen wir alle Zeilen, in denen Daten fehlen, um sicherzustellen, dass unsere Analyse nur auf vollständigen Daten basiert.\n",
    "\n",
    "Anschließend fügen wir in der studentInfo.csv Datei eine neue Spalte namens has_withdrawn hinzu. Diese Spalte ist ein boolesches Flag, das angibt, ob ein Student seinen Studiengang abgebrochen hat oder nicht. Wir erstellen diese Spalte, indem wir das final_result Feld jedes Studenten überprüfen und True setzen, wenn das Ergebnis 'Withdrawn' ist, und False sonst. Diese neue Spalte wird uns später helfen, das Muster des Studienabbruchs besser zu verstehen und zu analysieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from cassandra.cluster import Cluster, BatchStatement, ExecutionProfile,  EXEC_PROFILE_DEFAULT\n",
    "from cassandra.policies import DCAwareRoundRobinPolicy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_info = pd.read_csv('../data/studentInfo.csv')\n",
    "student_vle = pd.read_csv('../data/studentVle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning: removing lines with missing values\n",
    "student_info = student_info.dropna()\n",
    "student_vle = student_vle.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column indicating whether a student has withdrawn\n",
    "student_info['has_withdrawn'] = student_info['final_result'] == 'Withdrawn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einrichtung der Cassandra-Datenbank\n",
    "\n",
    "Zur Einrichtung unserer Datenbank in Cassandra führen wir zunächst einen Befehl aus, um einen neuen Keyspace namens 'oulad' zu erstellen. Ein Keyspace in Cassandra ist vergleichbar mit einer Datenbank in relationalen Datenbanksystemen und dient als Container für unsere Tabellen.\n",
    "\n",
    "Danach erstellen wir vier Tabellen innerhalb unseres Keyspace: student_info und student_vle. Jede dieser Tabellen entspricht einer der CSV-Dateien in unserem Dataset und enthält eine Reihe von Spalten, die den Feldern in der entsprechenden CSV-Datei entsprechen. Bei der Erstellung dieser Tabellen definieren wir auch die Primärschlüssel für jede Tabelle, die bestimmen, wie die Daten in der Tabelle verteilt und gespeichert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Cassandra tables\n",
    "\n",
    "# Create the cluster with contact points and load balancing policy\n",
    "cluster = Cluster(['cassandra'], port=9042)\n",
    "\n",
    "# Create a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS oulad \n",
    "    WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\n",
    "\"\"\")\n",
    "session.set_keyspace('oulad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f9f431ea080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define table for student_info\n",
    "session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS student_info (\n",
    "        id_student int,\n",
    "        code_module text,\n",
    "        code_presentation text,\n",
    "        gender text,\n",
    "        region text,\n",
    "        highest_education text,\n",
    "        imd_band text,\n",
    "        age_band text,\n",
    "        num_of_prev_attempts int,\n",
    "        studied_credits int,\n",
    "        disability text,\n",
    "        final_result text,\n",
    "        has_withdrawn boolean,\n",
    "        PRIMARY KEY(id_student, code_module, code_presentation)\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f9f431e9870>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table for student_vle\n",
    "session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS student_vle (\n",
    "        code_module text,\n",
    "        code_presentation text,\n",
    "        id_student int,\n",
    "        id_site int,\n",
    "        date int,\n",
    "        sum_click int,\n",
    "        PRIMARY KEY (id_student, id_site, date)\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten in Cassandra einfügen\n",
    "Das Einfügen von Daten in Cassandra wird über die execute-Methode einer Session realisiert. In unserem Fall verwenden wir jedoch eine spezielle Methode namens BatchStatements, um die Effizienz zu verbessern.\n",
    "\n",
    "BatchStatements erlauben es uns, mehrere Anweisungen als ein einzelnes Paket auszuführen, das zur Ausführung an Cassandra gesendet wird. Es handelt sich um eine praktische Möglichkeit, mehrere Aktualisierungen auf einmal durchzuführen und Netzwerkroundtrips zu minimieren.\n",
    "\n",
    "Zunächst wird ein BatchStatement-Objekt erstellt. Dann wird eine vorbereitete Einfügeanweisung erstellt, die auf die zuvor erstellten Cassandra-Tabellen abzielt. Die Platzhalter ? in der Einfügeanweisung werden später durch die tatsächlichen Datenwerte ersetzt.\n",
    "\n",
    "Danach durchlaufen wir jede Zeile des Pandas-Dataframe und fügen die Datenwerte in das BatchStatement ein. Wenn das BatchStatement zehn Datenzeilen erreicht, wird es ausgeführt und das BatchStatement geleert. Dieser Prozess wird wiederholt, bis alle Daten in das BatchStatement eingefügt und in Cassandra eingefügt sind.\n",
    "\n",
    "Dieses Verfahren ist nicht nur effizient, sondern ermöglicht auch eine ordnungsgemäße Verwaltung der Datenladung. Sollte ein Fehler während der Ausführung eines Batchs auftreten, werden nur die Anweisungen in diesem speziellen Batch nicht ausgeführt, während die vorherigen und nachfolgenden Batches nicht betroffen sind.\n",
    "\n",
    "Es ist zu beachten, dass, obwohl BatchStatements effizient sind, ihre übermäßige Verwendung vermieden werden sollte, da sie mehr Ressourcen als einzelne Anweisungen verbrauchen können. In unserem Fall ist die Verwendung von BatchStatements gerechtfertigt, da wir mit einer großen Menge an Daten arbeiten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert data into Cassandra using batches\n",
    "def insert_into_cassandra(data_frame, table_name):\n",
    "    batch = BatchStatement()\n",
    "    query = session.prepare(f\"INSERT INTO {table_name} ({','.join(data_frame.columns)}) VALUES ({','.join(['?' for _ in data_frame.columns])})\")\n",
    "\n",
    "    for _, row in data_frame.iterrows():\n",
    "        batch.add(query, tuple(row))\n",
    "        if len(batch) == 10:\n",
    "            session.execute(batch)\n",
    "            batch.clear()\n",
    "\n",
    "    if len(batch) > 0:\n",
    "        session.execute(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Cassandra for student_info table\n",
    "insert_into_cassandra(student_info, 'student_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Cassandra for student_vle table\n",
    "insert_into_cassandra(student_vle, 'student_vle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung einer erweiterten Tabelle und Zusammenführung der Daten\n",
    "\n",
    "Nachdem die grundlegenden Tabellen in Cassandra erstellt und mit Daten gefüllt wurden, wollen wir nun eine erweiterte Tabelle erstellen. Diese erweiterte Tabelle soll zusätzliche Informationen enthalten, die für unsere Analyse von Bedeutung sind.\n",
    "\n",
    "Die Tabelle student_vle_extended wird erstellt, um Daten aus der student_vle-Tabelle mit Informationen aus der student_info-Tabelle zusammenzuführen. Die Absicht dabei ist es, eine umfassendere Datenansicht zu erzeugen, die sowohl Informationen über die Interaktion der Studierenden mit dem virtuellen Lernumfeld (VLE) als auch über ihre persönlichen Informationen enthält.\n",
    "\n",
    "Besonders wichtig für unsere Analyse ist das Feld has_withdrawn, das wir zuvor in der student_info-Tabelle erstellt haben. Diese Information wird nun in die student_vle_extended-Tabelle aufgenommen, damit wir leichter Untersuchungen zum Studienabbruch durchführen können.\n",
    "\n",
    "Um die Zusammenführung der Daten zu bewerkstelligen, verwenden wir die Merge-Funktion der pandas-Bibliothek. Dies erlaubt es uns, die beiden Dataframes anhand von gemeinsamen Spalten, in diesem Fall id_student, code_module und code_presentation, zu verbinden. Das Ergebnis dieser Operation ist ein neuer Dataframe, der alle Spalten aus beiden ursprünglichen Dataframes enthält.\n",
    "\n",
    "Schließlich werden die Daten aus dem zusammengeführten Dataframe in die student_vle_extended-Tabelle in Cassandra eingefügt, ähnlich wie wir es zuvor getan haben. Nun haben wir eine erweiterte und bereinigte Datenansicht, die bereit für die weitere Analyse ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS student_vle_extended (\n",
    "        id_student int,\n",
    "        code_module text,\n",
    "        code_presentation text,\n",
    "        id_site int,\n",
    "        date int,\n",
    "        sum_click int,\n",
    "        has_withdrawn boolean,\n",
    "        PRIMARY KEY (id_student, code_module, code_presentation, id_site, date)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Merge two dataframes\n",
    "merged_data = pd.merge(student_vle, student_info[['id_student', 'code_module', 'code_presentation', 'final_result']], on=['id_student', 'code_module', 'code_presentation'], how='left')\n",
    "merged_data['has_withdrawn'] = merged_data['final_result'] == 'Withdrawn'\n",
    "\n",
    "# Insert data into table\n",
    "batch = BatchStatement()\n",
    "\n",
    "# Function to insert data into student_vle_extended\n",
    "def insert_into_student_vle_extended(row, batch):\n",
    "    prepared = session.prepare(\"\"\"\n",
    "        INSERT INTO student_vle_extended (id_student, code_module, code_presentation, id_site, date, sum_click, has_withdrawn)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    batch.add(prepared, (int(row['id_student']), row['code_module'], row['code_presentation'], int(row['id_site']), int(row['date']), int(row['sum_click']), bool(row['has_withdrawn'])))\n",
    "    if len(batch) == 10:\n",
    "        session.execute(batch)\n",
    "        batch.clear()\n",
    "\n",
    "# Apply the insertion function to merged_data\n",
    "merged_data.apply(insert_into_student_vle_extended, args=(batch,), axis=1)\n",
    "\n",
    "# Execute the remaining batch\n",
    "if len(batch) > 0:\n",
    "    session.execute(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am Ende des Prozesses trennen wir die Verbindung zur Datenbank, um Ressourcen freizugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
